{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring and Processing Information on the World's Largest Banks\n",
    "\n",
    "In this project, we will work with real-world data and perform the operations of Extraction, Transformation, and Loading (ETL) as required.\n",
    "\n",
    "- Task 1: Logging function\n",
    "- Task 2: Extraction of data\n",
    "- Task 3: Transformation of data\n",
    "- Task 4: Loading to CSV\n",
    "- Task 5: Loading to Database\n",
    "- Task 6: Function to Run queries on Database\n",
    "- Task 7: Verify log entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries: Installing libraries and downloading data\n",
    "\n",
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas bs4 wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the required exchange rate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the CSV data first into a local `exchange_rate.csv` file\n",
    "import wget\n",
    "wget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress generated warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Logging function\n",
    "\n",
    "This function accepts the message to be logged and enters it to the log file on a new line.\n",
    "\n",
    "Log entries will be in the format: `<timestamp> : <message>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing'''\n",
    "\n",
    "    timestamp_format = \"%Y-%h-%d-%H:%M:%S\" # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file,\"a\") as f:\n",
    "        f.write(timestamp + \" : \" + message + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Extraction of data\n",
    "\n",
    "1. Inspect the URL and identify the position and pattern of the tabular information in the HTML code under the heading `By market capitalization`. In the given webpage, our table is at the first position, or index 0 and we require the entries under *\"Bank name\"* and *\"Market cap (US$ billion)\"*.\n",
    "\n",
    "    <img src=\"List_of_largest_banks.png\">\n",
    "\n",
    "    Notice that all rows under this table are mentioned as `tr` objects under the table. Clicking one of them reveals that the data in each row is further saved as a `td` object. \n",
    "    \n",
    "    It is also important to note that entries under \"Bank name\" have two hyperlinks associated with it, one for the Country and the other for Bank name, as seen in the image above.\n",
    "\n",
    "2. Write the function `extract()` to retrieve the information of the table to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    ''' This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. '''\n",
    "\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    \n",
    "    df = pd.DataFrame(columns=table_attribs)\n",
    "    \n",
    "    tables = soup.find_all(\"tbody\")\n",
    "    rows = tables[0].find_all(\"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        col = row.find_all(\"td\")\n",
    "        if len(col) != 0:\n",
    "            data_dict = {\"Name\": col[1].find_all(\"a\")[1][\"title\"],\n",
    "                         \"MC_USD_Billion\": float(col[2].contents[0][:-1])}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code functions as follows:\n",
    "\n",
    "1. Extract the web page as text.\n",
    "1. Parse the text into an HTML object.\n",
    "1. Create an empty Pandas DataFrame named `df` with columns argument set as `table_attribs`.\n",
    "1. Extract all `tbody` attributes of the HTML object and then extract all the rows of the index 0 table using the `tr` attribute.\n",
    "1. Iterate over the contents of the variable `rows`.\n",
    "1. Extract all the `td` data objects in the row and save them to `col`.\n",
    "1. Check if the length of `col` is 0, that is, if there is no data in the current row. This is important since, many times there are merged rows that are not apparent in the web page appearance.\n",
    "1. Create a dictionary `data_dict` with the keys same as the columns of the dataframe created for recording the output earlier and corresponding values from the second and third headers of data.\n",
    "    - Extract the `title` attribute of the second hyperlink from the `Bank name` column.\n",
    "    - Remove the last character (`\\n`) from the `Market cap (US$ billion)` column contents using negative index slicing, then typecast the value to `float` format.\n",
    "1. Convert the dictionary to a dataframe and concatenate it with the existing one. This way, the data keeps getting appended to the dataframe with every iteration of the loop.\n",
    "1. Return the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Transformation of data\n",
    "\n",
    "The Transform function needs to perform the following tasks:\n",
    "\n",
    "1. Read the exchange rate CSV file and convert the contents to a dictionary so that the contents of the first columns are the keys to the dictionary and the contents of the second column are the corresponding values.\n",
    "\n",
    "1. Add 3 different columns to the dataframe: `MC_GBP_Billion`, `MC_EUR_Billion` and `MC_INR_Billion`, each containing the content of MC_USD_Billion scaled by the corresponding exchange rate factor. Round the resulting data to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, csv_path):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "\n",
    "    # Read exchange rate CSV file\n",
    "    exchange_rate = pd.read_csv(csv_path)\n",
    "\n",
    "    # Convert to a dictionary with \"Currency\" as keys and \"Rate\" as values\n",
    "    exchange_rate = exchange_rate.set_index(\"Currency\").to_dict()[\"Rate\"]\n",
    "\n",
    "    # Add MC_GBP_Billion, MC_EUR_Billion, and MC_INR_Billion\n",
    "    # columns to dataframe. Round off to two decimals\n",
    "    df[\"MC_GBP_Billion\"] = [np.round(x * exchange_rate[\"GBP\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    df[\"MC_EUR_Billion\"] = [np.round(x * exchange_rate[\"EUR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "    df[\"MC_INR_Billion\"] = [np.round(x * exchange_rate[\"INR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Loading to CSV\n",
    "\n",
    "Load the transformed dataframe to an output CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    ''' This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.'''\n",
    "\n",
    "    df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Loading to Database\n",
    "\n",
    "Load the transformed dataframe to a SQL database server as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.'''\n",
    "\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6: Function to Run queries on Database\n",
    "\n",
    "Run queries on the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running ETL Process\n",
    "\n",
    "Declaring known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "csv_path = \"./exchange_rate.csv\"\n",
    "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
    "output_path = \"./Largest_banks_data.csv\"\n",
    "db_name = \"Banks.db\"\n",
    "table_name = \"Largest_banks\"\n",
    "log_file = \"./code_log.txt\"\n",
    "\n",
    "log_progress(\"Preliminaries complete. Initiating ETL process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call extract() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract(url, table_attribs)\n",
    "print(df)\n",
    "\n",
    "log_progress(\"Data extraction complete. Initiating Transformation process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call transform() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform(df, csv_path)\n",
    "print(df)\n",
    "\n",
    "log_progress(\"Data transformation complete. Initiating Loading process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call load_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_csv(df, output_path)\n",
    "\n",
    "log_progress(\"Data saved to CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate SQLite3 connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_connection = sqlite3.connect(db_name)\n",
    "\n",
    "log_progress(\"SQL Connection initiated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call load_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "log_progress(\"Data loaded to Database as a table, Executing queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call run_query()\n",
    "\n",
    "1. Print the contents of the entire table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_statement = f\"SELECT * from {table_name}\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print the average market capitalization of all the banks in Billion GBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "run_query(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print only the names of the top 5 banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_statement = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress(\"Process Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close SQLite3 connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_connection.close()\n",
    "\n",
    "log_progress(\"Server Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7: Verify log entries\n",
    "\n",
    "Upon successful completion of execution, you should see all the relevant entries made in the log file in relation to the stages of code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_file, \"r\") as log:\n",
    "    LogContent = log.read()\n",
    "    print(LogContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-03-25  | 0.1  | Pravin Regismond | Initial version |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
